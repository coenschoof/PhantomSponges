{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "configuration:\n",
    "models_ver - insert YOLO version's numbers that the UAP will be trained on.\n",
    "\n",
    "epsilon, lambda_1, lambda_2 - attack's parameters. more information can be found in the [paper](https://arxiv.org/abs/2205.13618)\n",
    "\n",
    "BDD_IMG_DIR - a path to the BDD validation set images (or any other wanted dataset)\n",
    "\n",
    "BDD_LAB_DIR - a path to the BDD validation set labels (or any other wanted dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models_vers = [5] # for example: models_vers = [5] or models_vers = [3, 4, 5]\n",
    "epsilon = 70\n",
    "lambda_1 = 1\n",
    "lambda_2 = 10\n",
    "seed = 42\n",
    "patch_size=(640,640)\n",
    "img_size=(640,640)\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "max_labels_per_img = 65\n",
    "BDD_IMG_DIR = '/Users/coenschoof/miniconda/envs/phantomsponges/BDD100K-to-YOLOV5/bdd_in_YOLOV5_train_newLabels/images/val'\n",
    "BDD_LAB_DIR = '/Users/coenschoof/miniconda/envs/phantomsponges/BDD100K-to-YOLOV5/bdd_in_YOLOV5_train_newLabels/labels/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load BDD dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coenschoof/miniconda/envs/phantomsponges/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from datasets.augmentations1 import train_transform\n",
    "from datasets.split_data_set_combined import SplitDatasetCombined_BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "\n",
    "# unzipped = zip(*batch)\n",
    "\n",
    "# numbers, letters = unzipped\n",
    "\n",
    "# print(numbers)  # Output: (1, 2, 3)\n",
    "# print(letters)  # Output: ('a', 'b', 'c')\n",
    "\n",
    "#dus ipv [(tensor, array, string), (tensor, array, string), (tensor, array, string)] hebben we\n",
    "# train_loader[0] bevat 8 images\n",
    "# train_loader[1] bevat alle labels per voor 8 images\n",
    "# train_loader[2] bevat paths naar 8 images\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def set_random_seed(seed_value, use_cuda=True):\n",
    "    numpy.random.seed(seed_value)  # cpu vars\n",
    "    torch.manual_seed(seed_value)  # cpu  vars\n",
    "    random.seed(seed_value)  # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)  # Python hash buildin\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  # needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = SplitDatasetCombined_BDD(\n",
    "            img_dir= BDD_IMG_DIR,\n",
    "            lab_dir= BDD_LAB_DIR,\n",
    "            max_lab=max_labels_per_img,\n",
    "            img_size=img_size,\n",
    "            transform=train_transform,\n",
    "            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader en val_loader \n",
    "train_loader, val_loader, test_loader = split_dataset(val_split=0.1,\n",
    "                                                      shuffle_dataset=True,\n",
    "                                                      random_seed=seed,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      ordered=False,\n",
    "                                                      collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, SubsetRandomSampler, RandomSampler\n",
    "\n",
    "# sampler = RandomSampler([0,1,2,3])\n",
    "\n",
    "# for i in sampler:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_xyxy_out = torch.tensor([[0.0156, 0.0312, 0.0781, 0.1094]])\n",
    "\n",
    "# patch_xyxy_out = torch.tensor([\n",
    "#                         [10/640, 20/640, 50/640, 70/640],  # [x1, y1, x2, y2]\n",
    "#                         [30/640, 40/640, 80/640, 100/640],\n",
    "#                         [60/640, 70/640, 120/640, 160/640],\n",
    "#                     ])\n",
    "\n",
    "# #intersect(patch_xyxy_out, clean_xyxy_out)\n",
    "\n",
    "# torch.min(clean_xyxy_out[:, 2:].unsqueeze(1).expand(1, 3, 2), patch_xyxy_out[:, 2:].unsqueeze(0).expand(1, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "# from PIL import Image\n",
    "\n",
    "# # Load the image using PIL\n",
    "# image = Image.open('/Users/coenschoof/miniconda/envs/phantomsponges/BDD100K-to-YOLOV5/bdd100k/images/100k/val/b1c9c847-3bda4659.jpg')\n",
    "\n",
    "# # Define the transformations to apply to the image\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "# # Apply the transformations to convert the image to a tensor\n",
    "# tensor = transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# # Inference\n",
    "# results = model(tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (img_batch, lab_batch, _) in val_loader:\n",
    "#     print(torch.stack(img_batch).size())\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "create UAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "yolov5s summary: 270 layers, 7235389 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n",
      "local_yolos/yolov5/weights/yolov5s.pt\n",
      "Epoch:  0\n",
      "saving png of current patch at epoch: 0, batch: 0/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9971527777777778\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.393|0.249|0.014|0.0\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9971279761904762\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.435|0.249|0.019|0.002\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9951537698412698\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.411|0.248|0.016|0.007\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.996904761904762\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.353|0.249|0.01|0.005\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9956001984126984\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.38|0.248|0.013|0.007\n",
      "saving png of current patch at epoch: 0, batch: 5/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9967261904761905\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.377|0.248|0.013|0.007\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9955555555555555\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.488|0.248|0.024|0.005\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9966865079365079\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.606|0.248|0.036|0.008\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9945535714285715\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.396|0.248|0.015|0.009\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9955605158730159\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.433|0.248|0.018|0.007\n",
      "saving png of current patch at epoch: 0, batch: 10/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9968055555555555\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.54|0.249|0.029|0.006\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.994811507936508\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.412|0.248|0.016|0.008\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9965178571428571\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.339|0.248|0.009|0.008\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9974801587301587\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.523|0.249|0.027|0.008\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9961061507936508\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.363|0.248|0.011|0.012\n",
      "saving png of current patch at epoch: 0, batch: 15/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.997906746031746\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.512|0.249|0.026|0.014\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9954513888888888\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.349|0.248|0.01|0.007\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9948164682539683\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.397|0.248|0.015|0.006\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9979414682539682\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.411|0.249|0.016|0.015\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.99625\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.455|0.249|0.021|0.006\n",
      "saving png of current patch at epoch: 0, batch: 20/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9967063492063492\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.57|0.249|0.032|0.015\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9967410714285714\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.416|0.248|0.017|0.01\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9949305555555555\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.423|0.248|0.017|0.012\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9970982142857143\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.438|0.249|0.019|0.013\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9962351190476191\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.327|0.249|0.008|0.016\n",
      "saving png of current patch at epoch: 0, batch: 25/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9966964285714286\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.464|0.248|0.022|0.015\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9973660714285715\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.398|0.249|0.015|0.024\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9978521825396826\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.367|0.249|0.012|0.019\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.996264880952381\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.787|0.248|0.054|0.011\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9961061507936508\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.417|0.248|0.017|0.016\n",
      "saving png of current patch at epoch: 0, batch: 30/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9960912698412698\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.398|0.248|0.015|0.02\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9962847222222222\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.361|0.248|0.011|0.014\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9963194444444444\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.34|0.248|0.009|0.015\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9960813492063492\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.473|0.249|0.022|0.023\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9968055555555555\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.472|0.248|0.022|0.023\n",
      "saving png of current patch at epoch: 0, batch: 35/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9953075396825397\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.428|0.248|0.018|0.014\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9978323412698412\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.489|0.249|0.024|0.02\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9969593253968254\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.423|0.249|0.017|0.013\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.996641865079365\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.339|0.249|0.009|0.023\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9967757936507936\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.383|0.249|0.013|0.026\n",
      "saving png of current patch at epoch: 0, batch: 40/169...\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9967162698412698\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.445|0.248|0.02|0.025\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9953025793650794\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.461|0.248|0.021|0.013\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9966220238095238\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.412|0.249|0.016|0.031\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9937946428571428\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.386|0.247|0.014|0.013\n",
      "perc. of BB CSs < 0.25 (should decrease while training UAP) 0.9974603174603175\n",
      "combined_loss, max_obj, bb_area, iou_loss for this batch =               0.399|0.249|0.015|0.008\n",
      "saving png of current patch at epoch: 0, batch: 45/169...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m patch_name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_epsilon=\u001b[39m\u001b[39m{\u001b[39;00mepsilon\u001b[39m}\u001b[39;00m\u001b[39m_lambda1=\u001b[39m\u001b[39m{\u001b[39;00mlambda_1\u001b[39m}\u001b[39;00m\u001b[39m_lambda2=\u001b[39m\u001b[39m{\u001b[39;00mlambda_2\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m uap_phantom_sponge_attack \u001b[39m=\u001b[39m UAPPhantomSponge(patch_folder\u001b[39m=\u001b[39mpatch_name, \n\u001b[1;32m     12\u001b[0m                                              train_loader\u001b[39m=\u001b[39mtrain_loader, \n\u001b[1;32m     13\u001b[0m                                              val_loader\u001b[39m=\u001b[39mval_loader, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                              patch_size\u001b[39m=\u001b[39mpatch_size, \n\u001b[1;32m     19\u001b[0m                                              models_vers\u001b[39m=\u001b[39mmodels_vers)\n\u001b[0;32m---> 20\u001b[0m adv_img \u001b[39m=\u001b[39m uap_phantom_sponge_attack\u001b[39m.\u001b[39;49mrun_attack()\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/attack/uap_phantom_sponge.py:675\u001b[0m, in \u001b[0;36mUAPPhantomSponge.run_attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_attack\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 675\u001b[0m     tensor_adv_patch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpgd_L2(epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon, iter_eps\u001b[39m=\u001b[39;49m\u001b[39m0.0005\u001b[39;49m) \n\u001b[1;32m    677\u001b[0m     patch \u001b[39m=\u001b[39m tensor_adv_patch\n\u001b[1;32m    679\u001b[0m     \u001b[39m#schiet een plaatje van de final adv patch\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39m#slaat ook de train/val losses etc per epoch op en stopt ieder in een lijst\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/attack/uap_phantom_sponge.py:623\u001b[0m, in \u001b[0;36mUAPPhantomSponge.pgd_L2\u001b[0;34m(self, epsilon, iter_eps, min_x, max_x)\u001b[0m\n\u001b[1;32m    616\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(imgs)\n\u001b[1;32m    618\u001b[0m \u001b[39m#returnt middels FGSM een perturbed plaatje van 3x640x640\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m#adv_patch = bij epoch 0, batch 0 is dit een zwart plaatje (tensor met 0's)\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[39m#x = één tensor batch van 8 plaatjes\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m#label = een tuple van 8, elke entry bevat een np.array met elke row een bb, en columns [class, x-center, y-center, w, h]\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m#iter_eps = 0.0005, bepaalt de sterkte van de perturbation\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m adv_patch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfastGradientSignMethod(adv_patch, x, label, epsilon\u001b[39m=\u001b[39;49miter_eps)\n\u001b[1;32m    624\u001b[0m \u001b[39m#torch.save(adv_patch, f'self.full_patch_folder + tensor_{i}.pt')\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[39m#print(f\"adv_patch: {adv_patch}\")s\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m# Project the perturbation to the epsilon ball (L2 projection)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m# Neem het verschil tussen het zwarte plaatje en het perturbed zwarte plaatje\u001b[39;00m\n\u001b[1;32m    629\u001b[0m perturbation \u001b[39m=\u001b[39m adv_patch \u001b[39m-\u001b[39m patch\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/attack/uap_phantom_sponge.py:550\u001b[0m, in \u001b[0;36mUAPPhantomSponge.fastGradientSignMethod\u001b[0;34m(self, adv_patch, images, labels, epsilon)\u001b[0m\n\u001b[1;32m    544\u001b[0m penalty_term \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_penalty_term(images, images)\n\u001b[1;32m    545\u001b[0m \u001b[39m#applied_patch = batch + perturbation\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m#images = images van de batch\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m#labels = labels van de batch\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m#penatly_term = 0\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39m#adv_patch = zeroes van 3x640x640\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m data_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_function_gradient(applied_patch, images, labels, penalty_term,\n\u001b[1;32m    551\u001b[0m                                         adv_patch) \n\u001b[1;32m    553\u001b[0m \u001b[39m# Collect the element-wise sign of the data gradient\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39m#returnt -1, 0 of 1\u001b[39;00m\n\u001b[1;32m    555\u001b[0m sign_data_grad \u001b[39m=\u001b[39m data_grad\u001b[39m.\u001b[39msign()\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/attack/uap_phantom_sponge.py:503\u001b[0m, in \u001b[0;36mUAPPhantomSponge.loss_function_gradient\u001b[0;34m(self, applied_patch, init_images, batch_label, penalty_term, adv_patch)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    501\u001b[0m     \u001b[39m#WAT OUTPUT HET MODEL PRECIES?\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     output_clean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels[r](init_images)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m--> 503\u001b[0m output_patch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels[r](applied_patch)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    505\u001b[0m max_objects_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_objects(output_patch)\n\u001b[1;32m    506\u001b[0m bboxes_area_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbboxes_area(output_clean, output_patch)\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/local_yolos/yolov5/models/yolo.py:136\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_augment(x)  \u001b[39m# augmented inference, None\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_once(x, profile, visualize)\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/local_yolos/yolov5/models/yolo.py:159\u001b[0m, in \u001b[0;36mModel._forward_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 159\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    160\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/PhantomSponges/local_yolos/yolov5/models/yolo.py:57\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m z \u001b[39m=\u001b[39m []  \u001b[39m# inference output\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnl):\n\u001b[0;32m---> 57\u001b[0m     x[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm[i](x[i])  \u001b[39m# conv\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     bs, _, ny, nx \u001b[39m=\u001b[39m x[i]\u001b[39m.\u001b[39mshape  \u001b[39m# x(bs,255,20,20) to x(bs,3,20,20,85)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     x[i] \u001b[39m=\u001b[39m x[i]\u001b[39m.\u001b[39mview(bs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mna, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno, ny, nx)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 443\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda/envs/phantomsponges/lib/python3.9/site-packages/torch/nn/modules/conv.py:439\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    437\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    438\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 439\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    440\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from attack.uap_phantom_sponge import UAPPhantomSponge\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "patch_name = r\"yolov\"\n",
    "for ver in models_vers:\n",
    "  patch_name += f\"_{ver}\"\n",
    "patch_name += f\"_epsilon={epsilon}_lambda1={lambda_1}_lambda2={lambda_2}\"\n",
    "\n",
    "uap_phantom_sponge_attack = UAPPhantomSponge(patch_folder=patch_name, \n",
    "                                             train_loader=train_loader, \n",
    "                                             val_loader=val_loader, \n",
    "                                             epsilon = epsilon, \n",
    "                                             lambda_1=lambda_1, \n",
    "                                             lambda_2=lambda_2, \n",
    "                                             epochs=7,#stond hier voorheen nog niet\n",
    "                                             patch_size=patch_size, \n",
    "                                             models_vers=models_vers)\n",
    "adv_img = uap_phantom_sponge_attack.run_attack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
